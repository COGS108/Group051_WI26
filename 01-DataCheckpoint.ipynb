{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "TEAM LIST AND CREDITS\n",
    "\n",
    "Eljin Vedar\n",
    "Writing – original draft, Writing –  review & editing \n",
    "\n",
    "Isaac Chen\n",
    "Writing – original draft, Writing –  review & editing\n",
    "\n",
    "Jiafan Du\n",
    "Writing – original draft, Writing –  review & editing\n",
    "\n",
    "Robin Villareal\n",
    "Writing – original draft, Writing –  review & editing \n",
    "\n",
    "Barry Tunstall\n",
    "Writing – original draft, Writing –  review & editing \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“How well does performance on a Dance Dance Revolution chart with difficulty X, defined by the game’s numeric rating, predict a player’s overall skill level across songs of varying difficulty?”\n",
    "\n",
    "\n",
    "For this idea, we aim to address the new player approach to finding a difficulty range. For our rhythm game of interest, we will choose Dance Dance Revolution (DDR), a classic rhythm game. Starting out, it may feel like the game is too easy or too hard. Given pre-existing game stats, we will analyze the data given by a player to make a prediction of their current skill range, or what difficulty X number a player can attempt on average. Furthermore, with this prediction, we can go further into recommending new songs for a player to try out relative to their corresponding difficulty X.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As members of the Dance and Rhythm Game Club, we stand to address socioeconomic factors by making arcade rhythm games accessible. We understand the constraints of accessibility to an arcade, time, and disposable income play in being able to experience arcade rhythm games like Dance Dance Revolution (DDR) . It is one of our motivations to implore the general public to try DDR as we bring the arcade experience to campus. As we seek to expand our community, one of the problems we face when reaching out to new players is the willingness to try the game i.e not knowing where to begin. We run into phrases such as “I’m not good”, “I’ve never played before”, and even “I don’t even know where to start!” constantly. To that, we want to devise a method that involves a beginner friendly approach; easing players into DDR assuming they have no experience but an eagerness to learn. For the project, we used three sources based on their relevance to predictive analysis to form the foundation of our research.\n",
    "\n",
    " The paper, “Dance Dance Convolution,” [3](#ref3) is a study that attempts to generate DDR step charts based on machine learning, with two inputs - an audio file, and a desired difficulty. The model would then generate a fully playable chart by decomposing the task into two sequential prediction problems: first determining when steps should occur, and then determining which arrows should be placed at each predicted timing. The results were analyzed based on how similar they were to the original chart - things like average hold note length, arrow selection, and beat placement. The important conclusions that come from the study was the capacity to assign chart difficulty ratings for procedurally generated charts based on note densities, although limited to a max bpm of 120; expanded on in a revisit in 2025 [1](#ref1) which includes a refined version exceeding the 120 bpm threshold. Another useful prediction scheme was being able to predict the chart difficulty [2](#ref2) based on attributes we have assigned as step data and technique data. \n",
    "The main takeaway from the results of the paper, for our uses, is the conclusion that DDR charting aligns closely with underlying musical structure, and that difficulty can be linearly correlated with step frequency, rhythmic density, and other computationally extractable metrics. This is useful for our predictive modeling because it suggests that the player performance data we gather, such as timing accuracy, hit‑window distribution, and error frequency can also be correlated with chart difficulty in a uniform way. Thus, the same mathematical relationships that allow systems like DDC to infer difficulty from audio and chart context can be inverted in our analysis - we can infer a player's effective skill level by measuring how their accuracy degrades or holds steady across segments of varying structural difficulty.\n",
    "\n",
    "The “Dance Dance ConvLSTM” [1](#ref1) paper is an extension of this paper, diving deeper into subsections of charting in order to further quantify patterns that arise in step charting - correlated to chart triggers such as music speedups, slowdowns, or certain step patterns, such as repeated notes on the same arrow - these are usually considered to be more difficult to execute than standard patterning. [2](#ref2) This provides a further foundation for our analysis: if machine‑learning models can reliably infer difficulty from musical and structural cues, then player‑performance data should likewise reflect predictable responses to those same cues, enabling skill prediction through our structural‑difficulty analysis.\n",
    "\n",
    "The third paper, “Predicting Chart Difficulty in Rhythm Games Through Classification Using Chart Pattern Derived Attributes,” also deals with the subject of correlating the in-game difficulty numbers with actual difficulty. Their analysis deals with difficulty and correlating it with chart structure - The main conclusions from the paper, useful for our purposes, is that objective structural difficulty can be quantified and measured, and that the charting in the game’s maps is correlated with this difficulty. [3](#ref3) This is useful for us because it means that we can apply a similar analysis to player skill, since performance data (such as timing accuracy, error rate, and stamina degradation, etc.) should correlate with these same difficulty signifiers in the charts. Essentially, If difficulty can be reliably inferred from chart patterns, then player capability can be inferred from how well a player handles those patterns.\n",
    "\n",
    "From the articles and our own playing experience, we found 3 distinct data categories relevant to our project:\n",
    "1. Song Data (exact song) - data showing the title, artist, and folder the song is located in. This is important because there are versions of DDR that run on a different difficulty scale; making sure the songs user play are in the arcade version of the game.\n",
    "\n",
    "2. Chart Data (Difficulty X) - The degree of gameplay a player can encounter during a song. Individual songs in DDR can be played on varying difficulty levels. Each difficulty iteration is commonly referred to as a chart. Charts are given numerical values assigned by DDR from 1-20 (we will assign this number to X). As the number increases, players can expect an increase of notes on the screen (note density) and rhythmic patterns. Charts of equal value have the tendency to feature similar complexity. For example, Song A with difficulty 5 will be as equal as Song B with difficulty 5 in terms of chart complexity.\n",
    "\n",
    "3. Performance data (how a player does) - the overall score an individual obtains along with a timeline of where the player missed notes. This works in tandem with step data and technique data to evaluate what core fundamentals the person has/needs improvement on. In our project, we will use some of DDR's iconic scoring systems to assess new players (more info in HYPOTHESIS)\n",
    "\n",
    "\n",
    "\n",
    "Although these articles make great strides in the development of generated difficulty, we find the limitation of these contexts to engage with the new player community and the base game of DDR. Having the opportunity to expand on these works, we want to take chart predictions and the data acquired to contextualize them for the use of a new player; giving them a direction as they start their rhythm game journey.\n",
    "\n",
    "1. <a name=\"ref1\"> </a> O’Malley, Miguel. Dance Dance ConvLSTM. 2025, arXiv:2507.01644. https://arxiv.org/pdf/2507.01644\n",
    "2. <a name=\"ref2\"> </a>Caronongan, Arturo P., III, and Nelson A. Marcos. “Predicting Chart Difficulty in Rhythm Games Through Classification Using Chart Pattern Derived Attributes.” Computational Science and Technology, 2021, pp. 193–205. Springer Nature. https://link.springer.com/chapter/10.1007/978-981-33-4069-5_17\n",
    "3. <a name=\"ref3\"> </a>Donahue, Chris, Zachary C. Lipton, and Julian McAuley. “Dance Dance Convolution.” Proceedings of the 34th International Conference on Machine Learning, PMLR 70, 2017. https://proceedings.mlr.press/v70/donahue17a/donahue17a.pdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As players take on higher difficulty X ratings, DDR charts demand greater stamina, precision, and pattern recognition due to chart complexity increasing (i.e total stepcount, rhythms implemented, how many notes appear at once). Therefore, players who achieve EX% around the community avg EX% reflect the capacity to comprehend and execute these factors. We come to this conclusion since chart complexity can be generalized across songs of equal difficulty X rating; reflecting their underlying skill. \n",
    "\n",
    "\n",
    "We predict a strong correlation between a player's EX% reflecting their overall skill level when compared to the avg EX%.\n",
    "\n",
    "\n",
    "To analyze the skill of a player, we have used/adjusted preexisting variables DDR currently implements to assess players:\n",
    "1. Difficulty X - As stated previously, DDR difficulty has a rating numbered from easiest to hardest: 1-20. DDR includes 4 standard labels: BEGINNER 1-4 , BASIC 3-7, DIFFICULT 5-9, EXPERT 10-13+. One issue that has arisen was the overlapping ranges in the standard labels. As an example, one song can have a BASIC 7, while another song can have a DIFFICULT 7 even though there is no major difficulty spike between the two. For a new player, seeing DIFFICULT 7 instead of BASIC 7 may afflict a bias when choosing the difficulty. To avoid ambiguity, we want to simplify the system purely on the numeric RATING; assigning it to our variable, X (X can range from 1-20). When we refer to difficulty X now, it provides a clearer representation of difficulty while still utilizing the pre-existing DDR system. (a 7 is a 7!).\n",
    "\n",
    "\n",
    "2. EX - EX is a scoring system originating from DDR EXTREME; independent from the in game combo and life bar players use. EX was designed to be a timing-based accuracy score, given by the summation of the 2 best timing judgements - Marvelous and Perfect. To calculate EX, the formula is given below:\n",
    "        \n",
    "        EX = ∑ 2(Marvelous) + 1(Perfect)\n",
    "\n",
    "\n",
    "\n",
    "3. EX% - EX% is EX normalized. Because charts have varying total notecounts EX alone is\n",
    "Not enough to determine overall skill level. By normalizing EX, we obtain a metric that allows us to compare charts of different total notecounts. To calculate EX% we use the formula:\n",
    "        \n",
    "        EX% = EX/(3 x Total Notecount)\n",
    "\n",
    "\n",
    "4. median EX% (med EX%)  - The median EX% on a given song that will give us the baseline for a player's performance in relation to players who also attempted  chart difficulty X. We understand that one of the constraints of community-driven data is the possibility of inflated averages due to the data coming from registered users. These registered users offer a higher level of time commitment and scoring data than our new player demographic. For our project Median EX% is used to operationalize target performance that a player must achieve to be considered for that difficulty X skill level.\n",
    "\n",
    "\n",
    "5. Overall skill level - A player's overall skill level is operationalized as their individual EX% on a difficulty X chart in relation to the given difficulty X’s median EX%. This is best represented by the difficulty X they can reliably play.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "- Dataset #1\n",
    "  - Dataset Name: DDR BPI / Skill Attack data\n",
    "  - Link to the dataset:\n",
    "  - Number of observations: 5894\n",
    "\n",
    "  - Number of variables: 15\n",
    "\n",
    "  - Description of the variables most relevant to this project\n",
    "\n",
    "    1. DIFFICULTY X - Numeric difficulty of a song\n",
    "\n",
    "    2. Max EX - Maximum possible EX score on a given chart\n",
    "\n",
    "    3. PLAYERS - How many players attempted the given chart\n",
    "\n",
    "  - Descriptions of any shortcomings this dataset has with respect to the project\n",
    "\n",
    "    The dataset includes songs outside the arcade version of DDR. This does not affect the averages since they are calculated independently per song, but we will have to be cautious about players who attempt songs outside of the arcade version. Although songs outside the arcade version may adopt a difficulty X, there IS a noticeable spike in difficulty compared to an arcade song counterpart.\n",
    "\n",
    "- Dataset #2\n",
    "  - Dataset Name: Single (Chart Analyzer)\n",
    "  - Link to the dataset:\n",
    "  - Number of observations: 12866\n",
    "\n",
    "  - Number of variables: 260\n",
    "  - Description of the variables most relevant to this project\n",
    "\n",
    "    1. AC - A song is featured in the arcade version of the game\n",
    "    \n",
    "    2. INTL - the song is present in ALL regions an arcade version exists.\n",
    "\n",
    "\n",
    "  - Descriptions of any shortcomings this dataset has with respect to the project\n",
    "\n",
    "    Most of the relevant data overlaps with dataset 1 but is even more skewed because the averages are in tandem with all songs of a corresponding difficulty X, even if they are outside the arcade version of the game.\n",
    "\n",
    "- Dataset #3\n",
    "  - Dataset Name: Animefest Player Scores\n",
    "  - Link to the dataset:\n",
    "  - Number of observations: 198\n",
    "  - Number of variables: 49\n",
    "\n",
    "  - Description of the variables most relevant to this project\n",
    "    1. Title - What song they played\n",
    "    2. Difficulty - uses their beginner/basic/difficult/expert labels\n",
    "    3.  Score - EX scores are given as EX x 1,000,000\n",
    "\n",
    "  - Descriptions of any shortcomings this dataset has with repsect to the project\n",
    "  \n",
    "    Because the dataset uses the beginner/basic/difficult/expert labels we will have to search through the other sets for their numeric ratings. Another concern is the EX score is scaled by 1,000,000 so all EX scores from this dataset must be divided by 1,000,000 before it can be comparable to the averages.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/airline-safety/airline-safety.csv', 'filename':'airline-safety.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDR BPI/Skill Attack Performance\n",
    "\n",
    "The DDR BPI/Skill Attack Performance Dataset is a community-driven dataset that catalogs performance based statistics given by registered users who uploaded their playing data. Each row corresponds to a specific song, difficulty level/rating, and provides important statistics such as the average EX score obtained along and how many players were involved to produce those averages.\n",
    "The relevant columns from the dataset are as follows:\n",
    "\n",
    "diff - Numeric difficulty of a song. Can take a value between 1-20\n",
    "\n",
    "Max EX - Maximum possible EX score on a given chart\n",
    "\n",
    "PLAYERS - How many players attempted the given chart\n",
    "\n",
    "A central metric in this dataset is the EX score, which is the accuracy‑based scoring system that is the foundation of our project (EX Formula). These EX’s are important to log when we start converting them into EX%’s.\n",
    "\n",
    "One major concern of the dataset is how it is community-driven by registered users. We are building our averages on self-selected players who are willing to upload their scoring data for review. This may lead to introducing our target audience of newer players to the standards of the competitive scene. Through statistical analysis, we will attempt to make newer players comparable with some of the expected high averages.\n",
    "\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning: DDR BPI/Skill Attack Performance\n",
    "For dataset 1, the data itself was already in a usable format.\n",
    "The BPI dataset looks clean on the surface because it has consistent column names, each row represents one chart, numeric columns are mostly numeric, there are no obvious formatting errors, and the structure is already tidy (one row per chart, one column per variable)\n",
    "\n",
    "For dataset 1 all that is left for us is to eliminate columns and rows that are unnecessary for our project purpose such as the excess variables that we did not see as important or songs that are not part of the arcade version of DDR (which we will cross reference once we combine the data used from dataset 2).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 \n",
    "\n",
    "See instructions above for Dataset #1.  Feel free to keep adding as many more datasets as you need.  Put each new dataset in its own section just like these. \n",
    "\n",
    "Lastly if you do have multiple datasets, add another section where you demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets\n",
    "\n",
    "Please note that you can always keep adding more datasets in the future if these datasets you turn in for the checkpoint aren't sufficient.  The goal here is demonstrate that you can obtain and wrangle data.  You are not tied down to only use what you turn in right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #3\n",
    "\n",
    "See instructions above for Dataset #1.  Feel free to keep adding as many more datasets as you need.  Put each new dataset in its own section just like these. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planned Merges\n",
    "\n",
    "In the future we plan on developing a wrangled dataset using a combination of the important variables from dataset 1 and 2. The purpose of this dataset is to provide the us with a song encyclopedia devoid of songs outside the arcade version of DDR along with any other exclusives not accessible to new players. This will have the song TITLE of only (AC)(INTL) songs along with their corresponding DIFFICULTY X, Max EX%, median EX%, and amount of times the song was played. This dataset will be a unified dataset titled “DDR song Difficulty and Average Performance”. With this encyclopedia built we can make another unified data set that combines “DDR song Difficulty and Average Performance” to the “Animefest Player Scores”; assessing each player.\n",
    "\n",
    "### NOTES:\n",
    "\n",
    "At the time of the checkpoint, we have agreed the bias and skew of the data in dataset 1 that we will be computing median scores across all difficulty X's to serve as the baseline to better represent the new player demographic. and will work toward these developments and revisions for the EDA Checkpoint. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Keep the contents of this cell. For each item on the checklist\n",
    "-  put an X there if you've considered the item\n",
    "-  IF THE ITEM IS RELEVANT place a short paragraph after the checklist item discussing the issue.\n",
    "  \n",
    "Items on this checklist are meant to provoke discussion among good-faith actors who take their ethical responsibilities seriously. Your teams will document these discussions and decisions for posterity using this section.  You don't have to solve these problems, you just have to acknowledge any potential harm no matter how unlikely.\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "    We will be collecting data from AnimeFest, on February 14th using a DDR pad provided by the DRGC club on campus. We will brief attendees of our project, how their data is used, and that it is completely optional. We won’t be collecting signatures as it is already made anonymous by the software.\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    "    One form of collection bias we will encounter is the population we are sampling at AnimeFest. The majority of participants will most likely be UCSD students. Furthermore, we will be sampling from a small subset of UCSD students, those who are attending AnimeFest. However, we believe this bias will be negligible due to our other datasets being of varying age groups. Also, our goal is to collect a sample size of fifty to normalize the distribution.\n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "     PII will be minimized at AnimeFest since the software ensures anonymity.\n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "   Addressed downstream bias in constraint and limitations of community-driven averages (how we got avg EX%) and how this may be an unfair comparison.  At animefest, we tried to keep players on the same settings so we can evaluate them equally, but this also opens the constraint of players having different preferences when playing rhythm games. When evaluating player performance, we must reason with if their score is in the scope of the avg EX%. One way we devised was calculating the IQR across difficulty X’s.\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "       \n",
    "    No, one of our references is a “living” document of all player data and serves as a valuable resource to the rhythm game community.\n",
    "\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "\n",
    "    Relevant stakeholders include the high level/ optimization level players that are also accounted for in our dataset. This is something to be conscious about when looking at the scores relative to a predicted score of a new player. We have established a target demographic as the subject of interest in our rhythm game community. One other lingering concern would be DDR quality across all players. Some places do not take good care of their DDR machines and this leads to game impact (low sensitivity = losing score) and we acknowledge how this may affect averages.\n",
    "\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    "    One possible bias that we encounter will be in our dataset that takes in registered users. A possibility is that with a highly-motivated player base like DDR, there will be players who work on optimization of their scores and might play lower level difficulties for accuracy; these players will bring the average score up. This bias is mitigated by the large sample size.\n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    "    Yes. All player data involved in calculations are stripped independently from the individual who produced them and the players remain anonymous. At most, there is a tie to their in-game username, but that can be excluded as well.\n",
    "\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "     One of our resources is part of a living document that dates back almost 3 years ago.\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "\n",
    "   Our dataset does not include protected attributes such as race, gender, or age, so inherently our analysis cannot discriminate upon these characteristics. To avoid proxy discrimination we use DDR’s performance-based metrics that treats an individual as equal among other players such as difficulty X, EX, EX% and avg EX%.\n",
    "\n",
    "   \n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    "\n",
    "    For metrics we have developed 4 categories of data collection that all work in tandem with each other.\n",
    "       \n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "     We have communicated that our purpose is to appeal to the beginner/casual approach to starting rhythm games and the model will serve as a way to accommodate these members of our rhythm game community. Knowledge acquired through this data science may not serve a higher skill level, rather help reach out to those trying to get there.\n",
    "\n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "   \n",
    "   Our model is designed to help new DDR players understand difficulty ranges through the numeric rating, but we understand using data geared toward the DDR community can result in skewed data that represents the competitive DDR scene via registered users. However, as a community that strives for improvement, these players unintentionally set a bar for players coming in; a bar that appears daunting at first. We will try our best to still represent our target demographic of new players while acknowledging long-time players."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Expectation 1: Check Discord for Updates\n",
    "\n",
    "Team Expectation 2: Be transparent on scheduling/conflicts\n",
    "\n",
    "Team Expectation 3: If there are parts unclear about the project, bring it up as soon as possible\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Week|Main Task|Due Date| \n",
    "|:---:|---|:---:|\n",
    "|5 (2/4)| Edit, finalize, and submit proposal<br>Search for datasets|Proposal Due (2/4)| \n",
    "|6 (2/11)| Data Checkpoint:<br>• Animefest this weekend, acquire sample<br>• Wrangle data of references<br>• Logistics as specified in proposal<br>• Make sure we have a way of obtaining necessary variables<br>| N/A|\n",
    "|7 (2/18)|Edit, finalize, and submit Data checkpoint|Data Checkpoint Revisions (2/18)|\n",
    "|8 (2/25)|EDA checkpoint:<br>• Substantive analysis<br>• Multiple plots<br>• Summary statistics<br>• Early insights<br>• Potential issues (outliers, skew, missingness) |N/A|\n",
    "|9 (3/4)|Edit, finalize, and submit EDA checkpoint|EDA checkpoint Revisions (3/4)|\n",
    "|10 (3/11)|Video|N/A|\n",
    "|11 (3/18)|Edit, finalize, and submit Project|Whole Project + Video|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
